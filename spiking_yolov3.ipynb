{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.insert(0, './SpikingNN')\n",
    "\n",
    "from spiking_model import*\n",
    "\n",
    "import train as yolo_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Running on\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize data point indices for the data set batches\n",
    "def random_batch(seed, n, offset, train_split, validation_split, test_split):\n",
    "    indices = [i + offset for i in range(n)]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    train = np.array(indices[train_split.start - offset : train_split.stop - offset])\n",
    "    valid = np.array(indices[validation_split.start - offset: validation_split.stop - offset])\n",
    "    test = np.array(indices[test_split.start - offset : test_split.stop - offset])\n",
    "    \n",
    "    if n != len(np.unique(np.concatenate((train, valid, test)))): # Verify results\n",
    "        raise Exception(\"Malformed data batches\", len(train), len(valid), len(test))\n",
    "    return train, valid, test\n",
    "\n",
    "up = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "def inference(inference_type, conf_thres=0.1, iou_thres=0.5):\n",
    "    with torch.no_grad():\n",
    "        split = valid_set if inference_type == \"validation\" else test_set\n",
    "        print(\"Running\", inference_type)\n",
    "        yolo.test_init()\n",
    "        \n",
    "        running_loss = 0\n",
    "        pred_count = 0\n",
    "        start_time = time.time()\n",
    "        for i in split:\n",
    "            data, targets = load_data(i)\n",
    "            if len(targets) == 0 or i == 118 or i == 202:\n",
    "                print(\"\\tSkipping\", i)\n",
    "                continue\n",
    "\n",
    "            snn.reset_potentials()\n",
    "\n",
    "            for j in range(data.size()[0]):\n",
    "                input_data = data[j] / 5\n",
    "                snn.feed(input_data)\n",
    "\n",
    "            # Feed intermediate output to YOLO\n",
    "            intermediate = snn.collect() / data.size()[0] # Normalize ouputs to 0-1\n",
    "                \n",
    "            corner_to_center(targets)\n",
    "            yolo.test(intermediate, targets, i, data[-1], whwh, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "            pred_count += 1\n",
    "\n",
    "            print(\"\\t[%.0f] Real time: %.1fs\" % \n",
    "              (i, time.time() - start_time))\n",
    "            \n",
    "        map_score, losses = yolo.test_end()\n",
    "        print(inference_type.capitalize(), \"Time: %.0fs | mAP: %.4f\\n\" % \n",
    "              (time.time()-start_time, map_score), \"| Loss: \", losses, \"\\n\")\n",
    "        return map_score\n",
    "                \n",
    "def corner_to_center(targets):\n",
    "    for l in range(len(targets)):\n",
    "        # Move anchor from top left to center\n",
    "        targets[l][2] += targets[l][4]/2\n",
    "        targets[l][3] += targets[l][5]/2\n",
    "        \n",
    "def load_data(i):\n",
    "    return (torch.load(video_path + str(i) + \".pt\"), torch.load(bb_path + str(i) + \".pt\"))\n",
    "    \n",
    "def save_snn(snn, save_path):\n",
    "    torch.save(snn.state_dict(), snn_save_path)\n",
    "    print('Saved SNN', snn_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset variables\n",
    "video_path = \"N-Caltech101/tensor_data/\"\n",
    "bb_path = \"N-Caltech101/tensor_annotations/\"\n",
    "names = [\"Airplane\", \"Motorbike\"]  # Class names\n",
    "num_epochs = 100\n",
    "num_files = 1590\n",
    "file_offset = 5\n",
    "train_ratio = 0.8\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0\n",
    "validate = True\n",
    "test = False\n",
    "width = 240\n",
    "height = 176\n",
    "\n",
    "# YOLO variables\n",
    "yolo_load_file = './weights/spiking_best.pt'\n",
    "yolo_save_path = './weights/spiking_'\n",
    "yolo_cfg = \"../cfg/spiking-yolo.cfg\"  # YOLO config file\n",
    "whwh = torch.Tensor([398,269,345,223]).to(device)  # Output scaling for YOLO (approximated)\n",
    "\n",
    "# SNN variables\n",
    "snn_load_file = \"./weights/spiking_best.t7\"\n",
    "snn_save_path = \"./weights/spiking_\"\n",
    "snn_lr = 1e-5\n",
    "accum_grad = 25  # Number to batch gradients up before stepping back\n",
    "show_grad = False\n",
    "clip_thresh = math.inf  # Gradient clipping threshold (summed grad)\n",
    "use_scheduler = True\n",
    "sched_min = 1e-7  # Minimum lr multiplier for the scheduler\n",
    "init_gain = 2.25  # Random weight scaling for SNN \n",
    "decay = 0.75      # This ratio of membrane potential is removed each iteration\n",
    "\n",
    "load_snn = True\n",
    "load_yolo = True\n",
    "save = False\n",
    "\n",
    "train_split = range(file_offset, int(file_offset + train_ratio * num_files))\n",
    "validation_split = range(train_split.stop, int(train_split.stop + validation_ratio * num_files))\n",
    "test_split = range(validation_split.stop, int(validation_split.stop + test_ratio * num_files))\n",
    "train_set, valid_set, test_set = random_batch(78943522, num_files, file_offset, train_split, validation_split, test_split)\n",
    "\n",
    "# Init SNN\n",
    "snn = SCNN(device, decay=decay, init_gain=init_gain, input_size=(width, height, 2))\n",
    "if load_snn:\n",
    "    snn.load_state_dict(torch.load(snn_load_file))\n",
    "    print(\"Loaded SNN\", snn_load_file)\n",
    "\n",
    "print(snn)\n",
    "snn.to(device)\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=snn_lr)\n",
    "#optimizer = torch.optim.SGD(snn.parameters(), lr=snn_lr, momentum=0.937, nesterov=True)\n",
    "\n",
    "if use_scheduler:\n",
    "    # Cosine decay (https://arxiv.org/pdf/1812.01187.pdf). Is multiplied with lr for the specific epoch\n",
    "    lf = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1.0) * (1 - sched_min) + sched_min\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "    scheduler.last_epoch = 0 # starting_epoch - 1\n",
    "\n",
    "# Init YOLO\n",
    "yolo = yolo_model.Train(yolo_cfg, snn.c, num_epochs, accum_grad, train_split.stop - train_split.start, load_file=yolo_load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Decay:\", decay)\n",
    "print(\"SNN lr:\", snn_lr)\n",
    "print(\"Scheduled lr:\", sched_min)\n",
    "print(\"Decay:\", decay)\n",
    "print(\"Init gain:\", init_gain)\n",
    "print(\"Scheduler:\", use_scheduler)\n",
    "print(\"Pre-trained:\", load_snn, load_yolo, \"\\n\")\n",
    "\n",
    "inference(\"validation\")\n",
    "\n",
    "step_counter = 1\n",
    "best_map = 0\n",
    "maps = []\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch [%d/%d]' % (epoch+1, num_epochs))\n",
    "    running_loss = 0\n",
    "    pred_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in train_set:\n",
    "        data, targets = load_data(i)\n",
    "        \n",
    "        if len(targets) == 0 or i == 118 or i == 202: # Malformed data points \n",
    "            print(\"\\tSkip\", i)\n",
    "            continue\n",
    "        \n",
    "        snn.reset_potentials()\n",
    "\n",
    "        # - Forward -\n",
    "        for j in range(data.size()[0]):\n",
    "            input_data = data[j] / 5\n",
    "            snn.feed(input_data)\n",
    "            \n",
    "        # Feed intermediate output to YOLO\n",
    "        intermediate = snn.collect() / data.size()[0] # Normalize ouputs to 0-1\n",
    "\n",
    "        step = (step_counter == accum_grad)\n",
    "        if step:\n",
    "            step_counter = 1\n",
    "        else:\n",
    "            step_counter += 1\n",
    "                \n",
    "        loss = yolo.predict(intermediate, targets, step, i - file_offset, \n",
    "                            snn_grad=(snn.named_parameters() if show_grad and step else None))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred_count += 1\n",
    "        \n",
    "        # - Backward -\n",
    "        if step:\n",
    "            grad_size = torch.nn.utils.clip_grad_norm_(snn.parameters(), clip_thresh) # Avoid exploding gradient\n",
    "            #if grad_size > clip_thresh: \n",
    "            #    print(\"Gradient of size\", grad_size, \"clipped\")\n",
    "            optimizer.step()\n",
    "            snn.clear()\n",
    "            snn.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"\\t[%.0f] Real time: %.1fs | Loss: %.5f | Spike-rate: %.0f\" % \n",
    "          (i, time.time() - start_time, loss.item(), torch.sum(intermediate).item()), \n",
    "              \"| Grad: %.4f\" % grad_size if step else \"\")\n",
    "\n",
    "    if use_scheduler:\n",
    "        scheduler.step() \n",
    "\n",
    "    print(\"GPU: %.3gGB | Training loss: %.6f | Time: %.0fs\\n\" % \n",
    "          (torch.cuda.memory_cached() / 1e9, running_loss/pred_count, time.time()-start_time))\n",
    "    \n",
    "    if validate and validation_ratio:\n",
    "        map_score = inference(\"validation\")\n",
    "        maps.append(map_score)\n",
    "        \n",
    "    yolo.end_epoch()\n",
    "\n",
    "    if save:\n",
    "        save_snn(snn, snn_save_path + \"last.t7\")\n",
    "        yolo.save(yolo_save_path + \"last.pt\")\n",
    "        if validate and validation_ratio:\n",
    "            if map_score > best_map:\n",
    "                save_snn(snn, snn_save_path + \"best.t7\")\n",
    "                yolo.save(yolo_save_path + \"best.pt\")\n",
    "                best_map = map_score\n",
    "\n",
    "\n",
    "if len(maps) > 0:\n",
    "    print(\"All mAP scores\", maps)\n",
    "        \n",
    "if test and test_ratio:\n",
    "    inference(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
